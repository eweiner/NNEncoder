{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('base': conda)",
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "970457db39f82c487d3f1befe9f4f2815048c99927b3ebba7242308f6d6d8034"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import SimpleMNISTCNN, VanillaVAE\n",
    "from train import train_mnist, train_vae, generate_meta_dataloader, MNISTNetDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data(num_nets):\n",
    "    nets = []\n",
    "    outs = []\n",
    "    for _ in range(num_nets):\n",
    "        net, losses = train_mnist(SimpleMNISTCNN)\n",
    "        nets.append(net)\n",
    "        # print(accuracy)\n",
    "    return nets\n",
    "\n",
    "nets = get_data(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VanillaVAE(3015, 500, 6, 200, 500, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"200_trained_nets.pkl\", 'wb') as f:\n",
    "    pickle.dump(nets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"20_trained_nets.pkl\", 'rb') as f:\n",
    "    nets = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oldestest_nets = nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(nets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dset = MNISTNetDataset(nets, 64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl = generate_meta_dataloader(oldestest_nets, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Simpler model please"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def flat_to_net(flat_net):\n",
    "    with torch.no_grad():\n",
    "        test_net = SimpleMNISTCNN()\n",
    "        index = 0\n",
    "        for p in test_net.parameters():\n",
    "            end_index = torch.cumprod(torch.tensor(p.shape), 0)[-1] + index\n",
    "            p.copy_(flat_net[index:end_index].reshape(p.shape))\n",
    "            index = end_index\n",
    "        return test_net\n",
    "\n",
    "def train_vae(vae, dl, optimizer, losses=[], epochs=5,  use_reconstruction=True, batch_size=1, mnist_batch_size=256):\n",
    "    softmax = torch.nn.Softmax(dim=-1)\n",
    "    test = DataLoader(MNIST('.', train=False, transform=Compose([ToTensor(), Normalize((0.1307,), (0.3081,))])), batch_size = mnist_batch_size, shuffle=True)\n",
    "\n",
    "    for _ in tqdm(range(epochs)):\n",
    "        for nets in dl:\n",
    "            optimizer.zero_grad()\n",
    "            mean, std, output = vae.forward_train(nets)\n",
    "            dist_loss = vae.calc_loss(mean, std, constant=0.005)\n",
    "\n",
    "            # \n",
    "            new_nets = [flat_to_net(flat) for flat in output]\n",
    "            old_nets = [flat_to_net(n) for n in nets]\n",
    "            symmetric_kl = 0\n",
    "            total = 0\n",
    "            # print(\"Running the new nets stuff\")\n",
    "            for old_net, new_net in zip(old_nets, new_nets):\n",
    "                for mnist_batch, _ in test:\n",
    "                    total += 1.0\n",
    "                    new_out = softmax(new_net(mnist_batch))\n",
    "                    with torch.no_grad():\n",
    "                        old_out = softmax(old_net(mnist_batch))\n",
    "                        older_out = softmax(oldestest_nets[0](mnist_batch))\n",
    "                    # symmetrized KL\n",
    "                    # print(torch.log(old_out / (new_out + 1e-8)))\n",
    "                    # print(\"Old out shape: \", old_out.shape)\n",
    "                    # print(\"New out shape: \", new_out.shape)\n",
    "                    symmetric_kl += torch.sum((0.5 * torch.log((old_out + 1e-8) / (new_out + 1e-8)) * old_out + 0.5 * torch.log((new_out + 1e-8) / (old_out + 1e-8)) * new_out)) / new_out.shape[0]\n",
    "                    # print(\"New: \", new_out[0])\n",
    "                    # print(\"Old: \", old_out[0])\n",
    "                    # print(\"OG: \", older_out[0])\n",
    "                    # print(symmetric_kl)\n",
    "                    break\n",
    "            # print(\"Pre division symmetric KL:\", symmetric_kl)\n",
    "            # print(\"Total: \", total)\n",
    "            # print(\"Nets shape: \", nets.shape)\n",
    "            symmetric_kl /= total * nets.shape[0]\n",
    "            if use_reconstruction:\n",
    "                reconstruction = torch.sum((nets - output)**2) / nets.shape[0] / nets.shape[1]\n",
    "            else:\n",
    "                reconstruction = 0\n",
    "            print(\"Symmetric kl loss: \", symmetric_kl * 100)\n",
    "            print(\"Reconstruction loss: \", reconstruction *100)\n",
    "            print(\"Distribution loss: \", dist_loss)\n",
    "            vae_loss = symmetric_kl * 100 + reconstruction * 100 + dist_loss\n",
    "            vae_loss.backward()\n",
    "            losses.append(vae_loss.detach())\n",
    "            optimizer.step()\n",
    "            # print(vae_loss)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VanillaVAE(3015, 500, 3, 2, 500, 3)\n",
    "optimizer = torch.optim.Adam(vae.parameters())\n",
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "losses = train_vae(vae, dl, optimizer, losses=losses, epochs=300)\n",
    "\n",
    "# losses = train_vae(vae, dl, optimizer, losses=losses, epochs=100, use_reconstruction = False)\n",
    "# 1.12\n",
    "# 3015, 500, 3, 100, 500, 3 works :) visible on epoch ~35-40\n",
    "# 3015, 500, 3, 50, 500, 3 works :) visible on epoch ~35-40\n",
    "# 3015, 500, 3, 30, 500, 3 works (ish) :) visible on epoch ~35-40\n",
    "# 3015, 500, 3, 20, 500, 3 works (ish) :) visible on epoch ~35-40\n",
    "# 3015, 500, 3, 10, 500, 3 works (ish) :) visible on epoch ~35-40\n",
    "# 3015, 500, 3, 5, 500, 3 works (ish) :) visible on epoch ~35-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nets in dl:\n",
    "    print(nets)\n",
    "    print(vae(nets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "for x in dl:\n",
    "    mean, std, _ = vae.forward_train(x)\n",
    "    means.append(mean)\n",
    "means = torch.cat(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(means.shape)\n",
    "plt.scatter(means[:,0].detach(), means[:,1].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prof Gu meeting notes.... not worth trying to interpret without convo\n",
    "\n",
    "# 2 directions -> Use MNIST data\n",
    "# Look independent of data -> \"Metric\" in neural networks\n",
    "# Want theoretical results, think about cost function -> Convex, semi convex, bounded by convex.... Very interesting problem\n",
    "# Next thing I should try -> Analysis is easier for analysis from entropy idea\n",
    "# let v_i = |x_i - y_i|:  -sum((v_i) log |(v_i)|)\n",
    "# 1st, let it be intuitive, then find Riemannian metric -> Take features of last layer directly somehow\n",
    "# Currently have image data, basically done\n",
    "# Synthetic aperture radar data (SAR) -> Images. So many open problems\n",
    "# Weather, earthquakes, detect people underground\n",
    "# RICCI FLOW\n",
    "\n",
    "# Graph Ricci Curvature\n",
    "# Point net"
   ]
  }
 ]
}